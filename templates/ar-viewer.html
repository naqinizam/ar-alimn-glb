<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no, viewport-fit=cover">
    <title>AR Chair Debug</title>
    <style>
        #debug {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            background: rgba(0,0,0,0.9);
            color: white;
            padding: 10px;
            font-family: monospace;
            z-index: 10000;
            font-size: 14px;
        }
        #video-preview {
            position: fixed;
            top: 20px;
            right: 20px;
            width: 120px;
            height: 180px;
            z-index: 9999;
            border: 2px solid red;
        }
    </style>
</head>
<body style="margin: 0;">
    <div id="debug">Starting AR debug session...</div>
    <video id="video-preview" autoplay muted playsinline></video>

    <!-- 1. Load A-Frame FIRST -->
    <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
    
    <!-- 2. AR.js with NFT support -->
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

    <!-- 3. AR Scene -->
    <a-scene 
        vr-mode-ui="enabled: false"
        arjs="sourceType: webcam; detectionMode: mono; debugUIEnabled: true; trackingMethod: best;"
        renderer="logarithmicDepthBuffer: true; precision: medium;"
        embedded>

        <!-- Model with DEBUG MATERIAL -->
        <a-entity
            id="chair"
            gltf-model="url(/models/chair.glb)"
            scale="0.5 0.5 0.5"
            position="0 0 -1"
            material="color: #FF0000; metalness: 0; roughness: 1"
            arjs-anchor>
        </a-entity>

        <a-camera-static></a-camera-static>
    </a-scene>

    <script>
    const debug = document.getElementById('debug');
    const video = document.getElementById('video-preview');

    // 1. Verify camera stream
    navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
            video.srcObject = stream;
            debug.textContent += "\n‚úÖ Camera active";
        })
        .catch(err => {
            debug.textContent += `\n‚ùå Camera error: ${err.message}`;
        });

    // 2. Scene events
    const scene = document.querySelector('a-scene');
    const chair = document.getElementById('chair');

    scene.addEventListener('loaded', () => {
        debug.textContent += "\nüåê Scene loaded";
    });

    scene.addEventListener('arjs-video-loaded', () => {
        debug.textContent += "\nüìπ AR video ready";
    });

    scene.addEventListener('markerFound', () => {
        debug.textContent += "\nüéØ Surface detected";
    });

    chair.addEventListener('model-loaded', () => {
        debug.textContent += "\nü™ë Model loaded (check for RED chair)";
        // Force visible in case scale is wrong
        chair.setAttribute('scale', '0.5 0.5 0.5');
    });

    chair.addEventListener('model-error', (evt) => {
        debug.textContent += `\n‚ùå Model error: ${evt.detail?.message || 'Unknown'}`;
        console.error("Model error details:", evt.detail);
    });

    // 3. Timeout check
    setTimeout(() => {
        if (!document.querySelector('a-entity[gltf-model]').object3D.visible) {
            debug.textContent += "\n‚ö†Ô∏è Model invisible? Try:";
            debug.textContent += "\n- Moving phone slowly over textures";
            debug.textContent += "\n- Brighter lighting";
            debug.textContent += "\n- Checking console for errors";
        }
    }, 10000);
    </script>
</body>
</html>